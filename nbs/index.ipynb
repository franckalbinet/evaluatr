{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1453c57",
   "metadata": {},
   "source": [
    "# Evaluatr\n",
    "\n",
    "> AI-Powered Evaluation Report Framework Mapping and Synthesisa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a924d487",
   "metadata": {},
   "source": [
    "[![PyPI](https://img.shields.io/pypi/v/evaluatr)](https://pypi.org/project/evaluatr/)\n",
    "[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)\n",
    "[![Documentation](https://img.shields.io/badge/docs-GitHub%20Pages-blue)](https://franckalbinet.github.io/evaluatr/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a39efc",
   "metadata": {},
   "source": [
    "## What is Evaluatr?\n",
    "\n",
    "`Evaluatr` is an AI-powered system that automates mapping evaluation reports against structured frameworks while maintaining interpretability and human oversight. Initially developed for [IOM (International Organization for Migration)](https://www.iom.int) evaluation reports and the [Strategic Results Framework (SRF)](https://srf.iom.int), it transforms a traditionally manual, time-intensive process into an efficient, transparent workflow.\n",
    "\n",
    "The system maps evaluation reports against hierarchical frameworks like the SRF (objectives, enablers, cross-cutting priorities, outcomes, outputs, indicators) and connects to broader frameworks like the [Sustainable Development Goals (SDGs)](https://sdgs.un.org) for interoperability.\n",
    "\n",
    "Beyond automation, `Evaluatr` prioritizes **interpretability and human-AI collaboration**‚Äîenabling evaluators to understand the mapping process, audit AI decisions, perform error analysis, and build training datasets over time, ensuring the system aligns with organizational needs through actionable, transparent, auditable methodology."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6d25b1",
   "metadata": {},
   "source": [
    "## The Challenge We Solve\n",
    "\n",
    "IOM evaluators possess deep expertise in mapping evaluation reports against frameworks like the Strategic Results Framework (SRF), but face significant operational challenges when processing reports that often exceed 150 pages of diverse content across multiple projects and contexts.\n",
    "\n",
    "The core challenges are:\n",
    "\n",
    "- **Time-intensive process**: Hundreds of staff-hours required per comprehensive mapping exercise\n",
    "- **Individual consistency**: Even expert evaluators may categorize the same content differently across sessions\n",
    "- **Cross-evaluator consistency**: Different evaluators may interpret and map identical content to different framework outputs\n",
    "- **Scale vs. thoroughness**: Growing volume of evaluation reports creates pressure to choose between speed and comprehensive analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01d29dd",
   "metadata": {},
   "source": [
    "## Understanding Evaluation Mapping in the UN Context\n",
    "\n",
    "UN evaluation work encompasses several interconnected domains:\n",
    "\n",
    "- **Quality Check**: Assessing evidence quality and methodological rigor in evaluation reports\n",
    "- **Mapping/Tagging**: Identifying which standardized framework themes are central to each report\n",
    "- **Impact Evaluation**: Measuring program effectiveness using RCTs, quasi-experimental designs, etc.\n",
    "- **Synthesis**: Aggregating findings across reports on specific themes/regions to generate insights\n",
    "\n",
    "**Mapping/tagging** is a foundational step that identifies which themes from established evaluation frameworks (like IOM's Strategic Results Framework or the UN Global Compact for Migration) are *central* to each report. These frameworks provide agreed-upon nomenclature covering all relevant themes, ensuring common terminology across stakeholders and enabling interoperability for UN-wide aggregation and communication.\n",
    "\n",
    "Rather than extracting evidence for specific themes, mapping creates a curated index enabling evaluators to retrieve the most relevant reports for subsequent synthesis work, maximizing both precision (finding all relevant reports) and recall (avoiding irrelevant ones).\n",
    "\n",
    "::: {.callout-note}\n",
    "Throughout this documentation, we use \"mapping\" and \"tagging\" interchangeably.\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5a4301",
   "metadata": {},
   "source": [
    "## Key Features\n",
    "\n",
    "### 1. Document Preparation Pipeline ‚úÖ **Available**\n",
    "\n",
    "- **Repository Processing**: Read and preprocess IOM evaluation report repositories with standardized outputs\n",
    "- **Automated Downloads**: Batch download of evaluation documents from diverse sources\n",
    "- **OCR Processing**: Convert scanned PDFs to searchable text using Optical Character Recognition (OCR) technology\n",
    "- **Content Enrichment**: Fix OCR-corrupted headings and enrich documents with AI-generated image descriptions for high-quality input data\n",
    "\n",
    "### 2. AI-Assisted Framework Mapping ‚úÖ **Available**\n",
    "\n",
    "- **Multi-Stage Pipeline**: Three-stage mapping process that progressively narrows from broad themes ( SRF Enablers, Cross-cutting Priorities, GCM objectives) to specific SRF outputs. Each stage enriches context for the next‚Äîfor example, knowing a report is cross-cutting in nature helps accurately map specific SRF outputs\n",
    "- **Cost Optimization**: Leverages LLM prompt caching to minimize token usage and API costs during repeated analysis\n",
    "- **Command-line Interface**: Streamlined pipeline execution through easy-to-use CLI tools (`evl_ocr`, `evl_md_plus`, `evl_tag`)\n",
    "- **Transparent Tracing**: Complete audit trails of AI decisions stored for human review and evaluation\n",
    "\n",
    "### 3. Knowledge Synthesis üìã **Planned**\n",
    "\n",
    "- **Knowledge Cards**: Generate structured summaries for downstream AI tasks like proposal writing and synthesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69d4008",
   "metadata": {},
   "source": [
    "## Ô∏è Installation & Setup\n",
    "\n",
    "::: {.callout-tip}\n",
    "We recommend using isolated Python environments. [uv](https://docs.astral.sh/uv/concepts/projects/dependencies/) provides fast, reliable dependency management for Python projects.\n",
    ":::\n",
    "\n",
    "### From PyPI (Recommended)\n",
    "```bash\n",
    "pip install evaluatr\n",
    "```\n",
    "\n",
    "### From GitHub\n",
    "```bash\n",
    "pip install git+https://github.com/franckalbinet/evaluatr.git\n",
    "```\n",
    "\n",
    "### Development Installation\n",
    "```bash\n",
    "# Clone the repository\n",
    "git clone https://github.com/franckalbinet/evaluatr.git\n",
    "cd evaluatr\n",
    "\n",
    "# Install in development mode\n",
    "pip install -e .\n",
    "\n",
    "# Make changes in nbs/ directory, then compile:\n",
    "nbdev_prepare\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9134e3c0",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "This project uses [nbdev](https://nbdev.fast.ai) for literate programming - see the Development section for more details.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dfd81a",
   "metadata": {},
   "source": [
    "### Environment Configuration\n",
    "\n",
    "Create a `.env` file in your project root with your API keys:\n",
    "\n",
    "```bash\n",
    "MISTRAL_API_KEY=\"your_mistral_api_key\"\n",
    "GEMINI_API_KEY=\"your_gemini_api_key\"\n",
    "ANTHROPIC_API_KEY=\"your_anthropic_api_key\"\n",
    "```\n",
    "\n",
    "**Note**: Evaluatr uses [lisette](https://lisette.answer.ai), [LiteLLM](https://www.litellm.ai) and [DSPy](https://dspy.ai) for LLM interactions, giving you flexibility to use any compatible language model provider beyond the examples above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ef85cb",
   "metadata": {},
   "source": [
    "## Quick Start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de6657c",
   "metadata": {},
   "source": [
    "### Reading & standardizing evaluations repository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2ea544",
   "metadata": {},
   "source": [
    "For IOM evaluators working with the official evaluation repository, download the most recent evaluations from [evaluation.iom.int/evaluation-search-pdf](https://evaluation.iom.int/evaluation-search-pdf) as `.csv` file, then preprocess/standardize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f7ea28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### EVALUATION OF IOM‚ÄôS MIGRATION DATA STRATEGY\n",
       "**Year:** 2025 | **Organization:** IOM | **Countries:** Worldwide\n",
       "\n",
       "**Documents:** 2 available  \n",
       "**ID:** `9992310969aa2f428bc8aba29f865cf3`\n"
      ],
      "text/plain": [
       "Evaluation(id='9992310969aa2f428bc8aba29f865cf3', docs=[{'subtype': 'Evaluation report', 'url': 'https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/Annex%20VI%20Case%20Study%20-%20RDH%20East%2C%20Horn%20and%20Southern%20Africa.pdf', 'desc': 'Evaluation Report'}, {'subtype': 'Special related reports/documents', 'url': 'https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/Annex%20VII%20Case%20Study%20-%20RDH%20Asia-Pacific.pdf', 'desc': 'Evaluation Brief'}], meta={'Title': 'EVALUATION OF IOM‚ÄôS MIGRATION DATA STRATEGY', 'Year': 2025, 'Author': 'Data Conscious Ltd.', 'Best Practicesor Lessons Learnt': 'Yes', 'Date of Publication': '2025-08-11', 'Donor': nan, 'Evaluation Brief': 'Yes', 'Evaluation Commissioner': 'IOM', 'Evaluation Coverage': 'Global', 'Evaluation Period From Date': '2025-08-20', 'Evaluation Period To Date': '2025-05-31', 'Executive Summary': 'Yes', 'External Version of the Report': 'No', 'Languages': 'English', 'Migration Thematic Areas': 'Organisational policy/strategy', 'Name of Project(s) Being Evaluated': nan, 'Number of Pages Excluding annexes': 44.0, 'Other Documents Included': nan, 'Project Code': nan, 'Countries Covered': ['Worldwide'], 'Regions Covered': 'HQ Geneva', 'Relevant Crosscutting Themes': nan, 'Report Published': 'Yes', 'Terms of Reference': 'Yes', 'Type of Evaluation Scope': 'Strategy', 'Type of Evaluation Timing': \"Mid-term (during the project's implementation/programme)\", 'Type of Evaluator': 'External', 'Level of Evaluation': 'Centralized', 'Document Subtype': 'Evaluation report, Special related reports/documents', 'File URL': 'https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/Annex%20VI%20Case%20Study%20-%20RDH%20East%2C%20Horn%20and%20Southern%20Africa.pdf,   https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/Annex%20VII%20Case%20Study%20-%20RDH%20Asia-Pacific.pdf,   https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/Annex%20VIII%20-%20Inception%20Report.pdf,   https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/Evaluation%20Brief.pdf,   https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/IOM%20MDS%20Evaluation%20Report%20-%20clean_0.pdf,   https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/Migration%20Data%20Evaluation%20infographics.pdf', 'File description': 'Evaluation Report, Evaluation Brief, Annex VI Case Study - RDH East, Horn and Southern Africa, Annex VII Case Study - RDH Asia-Pacific, Annex VIII - Inception Report, Infographics', 'Management response': 'No', 'Date added': 'Thu, 08/07/2025 - 23:52'})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluatr.readers import IOMRepoReader\n",
    "\n",
    "fname = 'files/test/evaluation-search-export-11_13_2025--18_09_44.csv'\n",
    "reader = IOMRepoReader(fname)\n",
    "evals = reader()\n",
    "evals[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2578354c",
   "metadata": {},
   "source": [
    "To find a particular evaluation by `title` or `url`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef84306d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### Evaluation of IOM Accountability to Affected Populations\n",
       "**Year:** 2025 | **Organization:** IOM | **Countries:** Worldwide\n",
       "\n",
       "**Documents:** 4 available  \n",
       "**ID:** `6c3c2cf3fa479112967612b0baddab72`\n"
      ],
      "text/plain": [
       "Evaluation(id='6c3c2cf3fa479112967612b0baddab72', docs=[{'subtype': 'Evaluation report', 'url': 'https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/AAP%20Evaluation%20-%20Management%20Response%20Final.docx', 'desc': 'Evaluation Report'}, {'subtype': 'Evaluation brief', 'url': 'https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/AAP%20Evaluation%20Report_final_.pdf', 'desc': 'Evaluation Brief'}, {'subtype': 'Special related reports/documents', 'url': 'https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/AAP%20Infographics.pdf', 'desc': 'Infographic'}, {'subtype': 'Management response', 'url': 'https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/AAP_EN_Evaluation%20Brief_final_0.pdf', 'desc': 'Management Response'}], meta={'Title': 'Evaluation of IOM Accountability to Affected Populations', 'Year': 2025, 'Author': 'IOM CENTRAL EVALUATION', 'Best Practicesor Lessons Learnt': 'Yes', 'Date of Publication': '2025-01-01', 'Donor': 'IOM', 'Evaluation Brief': 'Yes', 'Evaluation Commissioner': 'IOM', 'Evaluation Coverage': 'Global', 'Evaluation Period From Date': 'nan', 'Evaluation Period To Date': 'nan', 'Executive Summary': 'Yes', 'External Version of the Report': 'No', 'Languages': 'English', 'Migration Thematic Areas': 'Multiple thematic overview, Organisational policy/strategy', 'Name of Project(s) Being Evaluated': nan, 'Number of Pages Excluding annexes': nan, 'Other Documents Included': nan, 'Project Code': nan, 'Countries Covered': ['Worldwide'], 'Regions Covered': 'Global', 'Relevant Crosscutting Themes': 'Accountability to affected populations, Gender, Principled humanitarian action, Rights-based approach', 'Report Published': 'Yes', 'Terms of Reference': 'Yes', 'Type of Evaluation Scope': 'Thematic', 'Type of Evaluation Timing': 'Not applicable', 'Type of Evaluator': 'Central/OIO', 'Level of Evaluation': 'Centralized', 'Document Subtype': 'Evaluation report, Evaluation brief, Special related reports/documents, Management response', 'File URL': 'https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/AAP%20Evaluation%20-%20Management%20Response%20Final.docx,   https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/AAP%20Evaluation%20Report_final_.pdf,   https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/AAP%20Infographics.pdf,   https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/AAP_EN_Evaluation%20Brief_final_0.pdf', 'File description': 'Evaluation Report , Evaluation Brief, Infographic, Management Response', 'Management response': 'No', 'Date added': 'Tue, 02/25/2025 - 18:33'})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluatr.readers import find_eval\n",
    "\n",
    "title = 'Evaluation of IOM Accountability to Affected Populations'\n",
    "find_eval(evals, title, by='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd00a9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### Evaluation of IOM Accountability to Affected Populations\n",
       "**Year:** 2025 | **Organization:** IOM | **Countries:** Worldwide\n",
       "\n",
       "**Documents:** 4 available  \n",
       "**ID:** `6c3c2cf3fa479112967612b0baddab72`\n"
      ],
      "text/plain": [
       "Evaluation(id='6c3c2cf3fa479112967612b0baddab72', docs=[{'subtype': 'Evaluation report', 'url': 'https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/AAP%20Evaluation%20-%20Management%20Response%20Final.docx', 'desc': 'Evaluation Report'}, {'subtype': 'Evaluation brief', 'url': 'https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/AAP%20Evaluation%20Report_final_.pdf', 'desc': 'Evaluation Brief'}, {'subtype': 'Special related reports/documents', 'url': 'https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/AAP%20Infographics.pdf', 'desc': 'Infographic'}, {'subtype': 'Management response', 'url': 'https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/AAP_EN_Evaluation%20Brief_final_0.pdf', 'desc': 'Management Response'}], meta={'Title': 'Evaluation of IOM Accountability to Affected Populations', 'Year': 2025, 'Author': 'IOM CENTRAL EVALUATION', 'Best Practicesor Lessons Learnt': 'Yes', 'Date of Publication': '2025-01-01', 'Donor': 'IOM', 'Evaluation Brief': 'Yes', 'Evaluation Commissioner': 'IOM', 'Evaluation Coverage': 'Global', 'Evaluation Period From Date': 'nan', 'Evaluation Period To Date': 'nan', 'Executive Summary': 'Yes', 'External Version of the Report': 'No', 'Languages': 'English', 'Migration Thematic Areas': 'Multiple thematic overview, Organisational policy/strategy', 'Name of Project(s) Being Evaluated': nan, 'Number of Pages Excluding annexes': nan, 'Other Documents Included': nan, 'Project Code': nan, 'Countries Covered': ['Worldwide'], 'Regions Covered': 'Global', 'Relevant Crosscutting Themes': 'Accountability to affected populations, Gender, Principled humanitarian action, Rights-based approach', 'Report Published': 'Yes', 'Terms of Reference': 'Yes', 'Type of Evaluation Scope': 'Thematic', 'Type of Evaluation Timing': 'Not applicable', 'Type of Evaluator': 'Central/OIO', 'Level of Evaluation': 'Centralized', 'Document Subtype': 'Evaluation report, Evaluation brief, Special related reports/documents, Management response', 'File URL': 'https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/AAP%20Evaluation%20-%20Management%20Response%20Final.docx,   https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/AAP%20Evaluation%20Report_final_.pdf,   https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/AAP%20Infographics.pdf,   https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/AAP_EN_Evaluation%20Brief_final_0.pdf', 'File description': 'Evaluation Report , Evaluation Brief, Infographic, Management Response', 'Management response': 'No', 'Date added': 'Tue, 02/25/2025 - 18:33'})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/AAP%20Evaluation%20Report_final_.pdf\"\n",
    "find_eval(evals, url, by='url')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8515fb0b",
   "metadata": {},
   "source": [
    "### Downloading Evaluation Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaa9541",
   "metadata": {},
   "source": [
    "```python\n",
    "from evaluatr.downloaders import download_docs\n",
    "from pathlib import Path\n",
    "\n",
    "fname = 'files/test/evaluations.json'\n",
    "base_dir = Path(\"files/test/pdf_library\")\n",
    "download_docs(fname, base_dir=base_dir, n_workers=0, overwrite=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7979161c",
   "metadata": {},
   "source": [
    "### Command Line Interface (CLI) Workflow\n",
    "\n",
    "Process any evaluation report from PDF to tagged outputs using three streamlined commands.\n",
    "\n",
    "**Example:** Given a report at `example-report-dir/example-report-file.pdf`\n",
    "\n",
    "**Step 1: OCR Processing**\n",
    "```bash\n",
    "evl_ocr example-report --pdf-dir . --output-dir md_library\n",
    "```\n",
    "\n",
    "**Step 2: Document Enrichment**\n",
    "```bash\n",
    "evl_md_plus example-report --md-dir md_library\n",
    "```\n",
    "\n",
    "**Step 3: Framework Tagging**\n",
    "```bash\n",
    "evl_tag example-report --md-dir md_library\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaf172f",
   "metadata": {},
   "source": [
    "### Detailed CLI Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b95bbe",
   "metadata": {},
   "source": [
    "#### `evl_ocr` - OCR Processing\n",
    "\n",
    "Convert PDF evaluation reports to structured markdown with extracted images.\n",
    "\n",
    "**Usage:**\n",
    "```bash\n",
    "evl_ocr <eval-id> [OPTIONS]\n",
    "```\n",
    "\n",
    "**Options:**\n",
    "\n",
    "- `--pdf-dir`: Directory containing PDF folders (default: `../data/pdf_library`)\n",
    "- `--output-dir`: Output directory for markdown (default: `../data/md_library`)\n",
    "- `--overwrite`: Reprocess if output already exists\n",
    "\n",
    "**Examples:**\n",
    "```bash\n",
    "# Basic usage\n",
    "evl_ocr example-report\n",
    "\n",
    "# Custom paths\n",
    "evl_ocr example-report --pdf-dir ./reports --output-dir ./markdown\n",
    "\n",
    "# Force reprocess\n",
    "evl_ocr example-report --overwrite\n",
    "```\n",
    "\n",
    "**Output Structure:**\n",
    "```\n",
    "md_library/\n",
    "‚îî‚îÄ‚îÄ example-report/\n",
    "    ‚îî‚îÄ‚îÄ example-report-file/\n",
    "        ‚îú‚îÄ‚îÄ page_1.md\n",
    "        ‚îú‚îÄ‚îÄ page_2.md\n",
    "        ‚îî‚îÄ‚îÄ img/\n",
    "            ‚îú‚îÄ‚îÄ img-0.jpeg\n",
    "            ‚îî‚îÄ‚îÄ img-1.jpeg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de4d42b",
   "metadata": {},
   "source": [
    "#### `evl_md_plus` - Document Enrichment\n",
    "\n",
    "Fix markdown headings hierarchy, append page numbers to each heading, and replace figures with AI-generated descriptions.\n",
    "\n",
    "**Usage:**\n",
    "```bash\n",
    "evl_md_plus <eval-id> [OPTIONS]\n",
    "```\n",
    "\n",
    "**Options:**\n",
    "\n",
    "- `--md-dir`: Directory containing markdown folders (default: `../data/md_library`)\n",
    "- `--overwrite`: Reprocess if enhanced/enriched already exists\n",
    "\n",
    "**Examples:**\n",
    "```bash\n",
    "# Basic usage\n",
    "evl_md_plus example-report\n",
    "\n",
    "# Force reprocess\n",
    "evl_md_plus example-report --overwrite\n",
    "```\n",
    "\n",
    "**Output:** Creates `enhanced/` and `enriched/` directories with corrected headings and image descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110a2268",
   "metadata": {},
   "source": [
    "#### `evl_tag`  [IOM only for now]\n",
    "\n",
    "Map evaluation reports against established frameworks (SRF, GCM) using AI-assisted analysis.\n",
    "\n",
    "**Usage:**\n",
    "```bash\n",
    "evl_tag <eval-id> [OPTIONS]\n",
    "```\n",
    "\n",
    "**Options:**\n",
    "\n",
    "- `--md-dir`: Directory containing markdown folders (default: `_data/md_library`)\n",
    "- `--stages`: Comma-separated stages to run (default: `1,2,3`)\n",
    "  - Stage 1: SRF Enablers & Cross-cutting Priorities\n",
    "  - Stage 2: GCM Objectives\n",
    "  - Stage 3: SRF Outputs\n",
    "- `--force-refresh`: Force refresh specific stages (comma-separated: `sections,stage1,stage2,stage3`)\n",
    "\n",
    "**Examples:**\n",
    "```bash\n",
    "# Run all stages\n",
    "evl_tag example-report\n",
    "\n",
    "# Run specific stages only\n",
    "evl_tag example-report --stages 1,2\n",
    "\n",
    "# Force refresh certain stages\n",
    "evl_tag example-report --force-refresh stage1,stage3\n",
    "\n",
    "# Combined options\n",
    "evl_tag example-report --stages 2,3 --force-refresh sections\n",
    "```\n",
    "\n",
    "**Output:** Results stored in `~/.evaluatr/traces/` with complete audit trails of AI decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6f3076",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "- **Full Documentation**: [GitHub Pages](https://franckalbinet.github.io/evaluatr/)\n",
    "- **Module Notebooks** (literate programming with nbdev):\n",
    "  - [OCR Processing](https://fr.anckalbi.net/evaluatr/ocr.html)\n",
    "  - [Document Enrichment](https://fr.anckalbi.net/evaluatr/enrichr.html)\n",
    "  - [Framework Mapping](https://fr.anckalbi.net/evaluatr/mappr.html)\n",
    "- **Examples**: See the `nbs/` directory for Jupyter notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcb3f97",
   "metadata": {},
   "source": [
    "## Contributing\n",
    "\n",
    "### Development Philosophy\n",
    "Evaluatr is built using [**nbdev**](https://nbdev.fast.ai), enabling documentation-driven development where code, docs, and tests live together in notebooks.\n",
    "\n",
    "### Adding CLI Commands\n",
    "We use [fastcore.script](https://fastcore.fast.ai/script.html) to create CLI tools. See the [nbdev console scripts tutorial](https://nbdev.fast.ai/tutorials/tutorial.html#advanced-functionality) for setup details.\n",
    "\n",
    "### Development Setup\n",
    "\n",
    "We welcome contributions! Here's how you can help:\n",
    "\n",
    "1. **Fork** the repository\n",
    "\n",
    "```bash\n",
    "# Install development dependencies\n",
    "pip install -e .\n",
    "\n",
    "```\n",
    "\n",
    "2. **Create** a feature branch (`git checkout -b feature/amazing-feature`)\n",
    "3. **Make** your changes in the `nbs/` directory\n",
    "4. **Compile** with `nbdev_prepare`\n",
    "5. **Commit** your changes (`git commit -m 'Add amazing feature'`)\n",
    "6. **Push** to the branch (`git push origin feature/amazing-feature`)\n",
    "7. **Open** a Pull Request\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e498929f",
   "metadata": {},
   "source": [
    "## License\n",
    "\n",
    "This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70e1255",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "See [`settings.ini`](settings.ini) for the complete list of dependencies. Key packages include:\n",
    "\n",
    "- **fastcore** & **pandas** - Core data processing\n",
    "- **lisette**, **litellm** & **dspy** - AI/LLM integration\n",
    "- **mistralai** - OCR processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce4281e",
   "metadata": {},
   "source": [
    "## Support\n",
    "\n",
    "- **Issues**: [GitHub Issues](https://github.com/franckalbinet/evalstack/issues)\n",
    "- **Discussions**: [GitHub Discussions](https://github.com/franckalbinet/evalstack/discussions)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
