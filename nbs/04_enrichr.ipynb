{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrichr\n",
    "\n",
    "> Fix, clean markdown headings and enrich it with figures description, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module aims to fix and enrich markdown headings from OCR'd PDF files by:\n",
    "\n",
    "1. Fixing heading hierarchy that was corrupted during OCR\n",
    "2. Adding page numbers to headings for better navigation\n",
    "3. Enriching figure references with descriptive text and creating a table of figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp enrichr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import shutil\n",
    "import time\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from fastcore.all import *\n",
    "import dspy\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "from litellm import completion\n",
    "import base64\n",
    "from rich import print\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "load_dotenv()\n",
    "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "cfg = AttrDict({\n",
    "    'enhanced_dir': 'enhanced',\n",
    "    'enriched_dir': 'enriched',\n",
    "    'lm': 'gemini/gemini-2.0-flash',\n",
    "    'api_key': GEMINI_API_KEY,\n",
    "    'max_tokens': 8192,\n",
    "    'track_usage': False,\n",
    "    'img_dir': 'img'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "src_dir = Path(\"../_data/md_library/49d2fba781b6a7c0d94577479636ee6f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "log_dir = Path.home() / '.evaluatr'\n",
    "log_dir.mkdir(exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(str(log_dir / 'enrichr.log')),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing Markdown Headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#142) [Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/page_1.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/page_2.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/page_3.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/page_4.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/page_5.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/page_6.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/page_7.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/page_8.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/page_9.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/page_10.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/page_11.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/page_12.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/page_13.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/page_14.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/page_15.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/page_16.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/page_17.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/page_18.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/page_19.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/page_20.md')...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "# doc = src_dir / 'abridged_evaluation_report_final_olta_ndoja_pdf'\n",
    "doc = src_dir / 'final_evaluation_report_final_olta_ndoja_pdf'\n",
    "pages = doc.ls(file_exts=\".md\").sorted(key=lambda p: int(p.stem.split('_')[1])); pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def setup_enhanced_dir(\n",
    "    src_dir, # Source directory path\n",
    "    enhanced_dir_name=cfg.enhanced_dir # Name of enhanced subdirectory\n",
    "    ):\n",
    "    \"Create enhanced directory and copy all markdown files to it\"\n",
    "    src_path = Path(src_dir)\n",
    "    enhanced_path = src_path / enhanced_dir_name\n",
    "    enhanced_path.mkdir(exist_ok=True)\n",
    "    for f in src_path.ls(file_exts=\".md\"): shutil.copy(f, enhanced_path)\n",
    "    return enhanced_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "setup_enhanced_dir(doc, 'enhanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_hdgs(md_txt): return re.findall(r'^#+.*$', md_txt, re.MULTILINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_hdgs_with_pages(\n",
    "    pages: list[Path] # List of pages\n",
    "    ):\n",
    "    \"Get headings and the page number they are on\"\n",
    "    headings = []\n",
    "    for i, page in enumerate(pages, 1):  # page numbers start at 1\n",
    "        page_headings = get_hdgs(page.read_text())\n",
    "        for o in page_headings: headings.append({'heading': o, 'page': i})\n",
    "    return headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'heading': '# **PPMi**', 'page': 1},\n",
       " {'heading': '# LIST OF FIGURES ', 'page': 5},\n",
       " {'heading': '# Abbreviations and terminology ', 'page': 6},\n",
       " {'heading': '# Key terminology ', 'page': 8},\n",
       " {'heading': '# Executive summary ', 'page': 10}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "hdgs = get_hdgs_with_pages(pages); hdgs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5) ['# **PPMi**','# LIST OF FIGURES ','# Abbreviations and terminology ','# Key terminology ','# Executive summary ']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "toc = L([get_hdgs(p.read_text()) for p in pages]).concat(); toc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def format_hdgs(\n",
    "    hdgs: list[dict] # List of headings with page numbers\n",
    "    ):\n",
    "    \"Format headings with page numbers\"\n",
    "    formatted = []\n",
    "    page_positions = {}\n",
    "    \n",
    "    for item in hdgs:\n",
    "        page = item['page']\n",
    "        page_positions[page] = page_positions.get(page, 0) + 1\n",
    "        formatted.append(f\"{item['heading']} (Page {page}, Position {page_positions[page]})\")\n",
    "    \n",
    "    return \"\\n\".join(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"># **PPMi** <span style=\"font-weight: bold\">(</span>Page <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Position <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "# LIST OF FIGURES  <span style=\"font-weight: bold\">(</span>Page <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, Position <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "# Abbreviations and terminology  <span style=\"font-weight: bold\">(</span>Page <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, Position <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "# Key terminology  <span style=\"font-weight: bold\">(</span>Page <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, Position <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "# Executive summary  <span style=\"font-weight: bold\">(</span>Page <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, Position <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "## Background <span style=\"font-weight: bold\">(</span>Page <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, Position <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "# Methodology  <span style=\"font-weight: bold\">(</span>Page <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, Position <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "# Findings  <span style=\"font-weight: bold\">(</span>Page <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>, Position <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "## Relevance <span style=\"font-weight: bold\">(</span>Page <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>, Position <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "# Coherence  <span style=\"font-weight: bold\">(</span>Page <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>, Position <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "## $<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.3</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>$ <span style=\"font-weight: bold\">(</span>Page <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>, Position <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "# Effectiveness  <span style=\"font-weight: bold\">(</span>Page <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>, Position <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "## Specific Outcome <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: <span style=\"font-weight: bold\">(</span>Page <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>, Positio\n",
       "</pre>\n"
      ],
      "text/plain": [
       "# **PPMi** \u001b[1m(\u001b[0mPage \u001b[1;36m1\u001b[0m, Position \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n",
       "# LIST OF FIGURES  \u001b[1m(\u001b[0mPage \u001b[1;36m5\u001b[0m, Position \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n",
       "# Abbreviations and terminology  \u001b[1m(\u001b[0mPage \u001b[1;36m6\u001b[0m, Position \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n",
       "# Key terminology  \u001b[1m(\u001b[0mPage \u001b[1;36m8\u001b[0m, Position \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n",
       "# Executive summary  \u001b[1m(\u001b[0mPage \u001b[1;36m10\u001b[0m, Position \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n",
       "## Background \u001b[1m(\u001b[0mPage \u001b[1;36m10\u001b[0m, Position \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n",
       "# Methodology  \u001b[1m(\u001b[0mPage \u001b[1;36m11\u001b[0m, Position \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n",
       "# Findings  \u001b[1m(\u001b[0mPage \u001b[1;36m12\u001b[0m, Position \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n",
       "## Relevance \u001b[1m(\u001b[0mPage \u001b[1;36m12\u001b[0m, Position \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n",
       "# Coherence  \u001b[1m(\u001b[0mPage \u001b[1;36m13\u001b[0m, Position \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n",
       "## $\u001b[1;36m4.3\u001b[0m \u001b[35m/\u001b[0m \u001b[1;36m5\u001b[0m$ \u001b[1m(\u001b[0mPage \u001b[1;36m13\u001b[0m, Position \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n",
       "# Effectiveness  \u001b[1m(\u001b[0mPage \u001b[1;36m14\u001b[0m, Position \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n",
       "## Specific Outcome \u001b[1;36m1\u001b[0m: \u001b[1m(\u001b[0mPage \u001b[1;36m14\u001b[0m, Positio\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "print(format_hdgs(hdgs)[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lm = dspy.LM(cfg.lm, api_key=cfg.api_key)\n",
    "dspy.configure(lm=lm)\n",
    "dspy.settings.configure(track_usage=cfg.track_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class HeadingResult(BaseModel):\n",
    "    old: str\n",
    "    page: int\n",
    "    position: int\n",
    "    new: str\n",
    "    changed: bool  # True if correction was made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class FixHeadingHierarchy(dspy.Signature):\n",
    "    \"\"\"Fix markdown heading hierarchy by analyzing the document's numbering patterns:\n",
    "    - Detect numbering scheme (1.2.3, I.A.1, A.1.a, etc.)\n",
    "    - Apply hierarchy levels based on nesting depth: # for top level, ## for second level, ### for third level\n",
    "    - When a section number is lower than a previously seen number at the same level (e.g., seeing '2.' after '3.1'), it's likely a subsection or list item, not a main section\n",
    "    - Unnumbered headings: keep as-is if at document boundaries, treat as subsections if within numbered sections\n",
    "    - Return ALL headings with their corrected form\n",
    "    \"\"\"\n",
    "    \n",
    "    headings_with_pages: str = dspy.InputField(desc=\"List of headings with page numbers\")\n",
    "    results: List[HeadingResult] = dspy.OutputField(desc=\"All headings with corrections and change status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def fix_md(\n",
    "    hdgs: list[dict], # List of headings with page numbers\n",
    "    track_usage: bool=cfg.track_usage,\n",
    "    ):\n",
    "    \"Fix markdown headings\"\n",
    "    lm = dspy.LM(cfg.lm, api_key=cfg.api_key, max_tokens=cfg.max_tokens)\n",
    "    dspy.configure(lm=lm)\n",
    "    dspy.settings.configure(track_usage=track_usage)\n",
    "\n",
    "    inp = format_hdgs(hdgs)\n",
    "    fix_hdgs = dspy.ChainOfThought(FixHeadingHierarchy)\n",
    "    result = fix_hdgs(headings_with_pages=inp)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "result = fix_md(hdgs, track_usage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def group_corrections_by_page(\n",
    "    results: list[HeadingResult], # List of headings with corrections and change status\n",
    "    ):\n",
    "    \"Group HeadingResult corrections by page number into dict with page nums as keys\"\n",
    "    page_groups = {}\n",
    "    for result in results:\n",
    "        page = result.page\n",
    "        if page not in page_groups:\n",
    "            page_groups[page] = []\n",
    "        page_groups[page].append(result)\n",
    "    return page_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "group_corrections_by_page(result.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def apply_corrections_to_page(\n",
    "    page_nb, # Page number\n",
    "    corrections, # List of corrections\n",
    "    enhanced_path, # Path to enhanced directory\n",
    "    ):\n",
    "    \"Apply corrections to a page in the enhanced directory\"\n",
    "    page_file = enhanced_path / f\"page_{page_nb}.md\"\n",
    "    lines = page_file.read_text().splitlines()\n",
    "    corrections_copy = corrections.copy()\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        for correction in corrections_copy:\n",
    "            if line.strip() == correction.old.strip():\n",
    "                lines[i] = f\"{correction.new} .... page {page_nb}\"\n",
    "                corrections_copy.remove(correction)\n",
    "                break\n",
    "            \n",
    "    page_file.write_text('\\n'.join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "enhanced_path = doc / cfg.enhanced_dir\n",
    "apply_corrections_to_page(5, result.results, enhanced_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def apply_all_corrections(\n",
    "    results, # List of headings with corrections and change status\n",
    "    enhanced_path, # Path to enhanced directory\n",
    "    ):\n",
    "    \"Apply all corrections to the pages in enhanced directory\"\n",
    "    grouped = group_corrections_by_page(results)\n",
    "    for page_nb, corrections in grouped.items(): \n",
    "        apply_corrections_to_page(page_nb, corrections, enhanced_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "apply_all_corrections(result.results, enhanced_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def fix_doc_hdgs(\n",
    "    src_dir, # Path to the folder containing the document\n",
    "    force=False, # Whether to overwrite the existing enhanced directory\n",
    "    ):\n",
    "    \"Process the document directory\"\n",
    "    src_path = Path(src_dir)\n",
    "    enhanced_path = src_path / cfg.enhanced_dir\n",
    "    \n",
    "    if enhanced_path.exists() and not force:\n",
    "        print(f\"Enhanced directory '{cfg.enhanced_dir}' already exists. Use force=True to overwrite.\")\n",
    "        return\n",
    "    if enhanced_path.exists() and force: \n",
    "        shutil.rmtree(enhanced_path)\n",
    "    \n",
    "    enhanced_path = setup_enhanced_dir(src_dir)\n",
    "    pages = enhanced_path.ls(file_exts=\".md\").sorted(key=lambda p: int(p.stem.split('_')[1]))\n",
    "    result = fix_md(get_hdgs_with_pages(pages))\n",
    "    apply_all_corrections(result.results, enhanced_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">..<span style=\"color: #800080; text-decoration-color: #800080\">/_data/md_library/49d2fba781b6a7c0d94577479636ee6f/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">final_evaluation_report_final_olta_ndoja_pdf</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "..\u001b[35m/_data/md_library/49d2fba781b6a7c0d94577479636ee6f/\u001b[0m\u001b[95mfinal_evaluation_report_final_olta_ndoja_pdf\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "print(doc)\n",
    "fix_doc_hdgs(doc, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrich with figures description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#142) [Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_1.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_2.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_3.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_4.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_5.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_6.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_7.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_8.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_9.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_10.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_11.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_12.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_13.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_14.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_15.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_16.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_17.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_18.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_19.md'),Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_20.md')...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "# doc = src_dir / 'abridged_evaluation_report_final_olta_ndoja_pdf/enhanced'\n",
    "doc = src_dir / 'final_evaluation_report_final_olta_ndoja_pdf/enhanced'\n",
    "pages = doc.ls(file_exts=\".md\").sorted(key=lambda p: int(p.stem.split('_')[1])); pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def has_images(page_path):\n",
    "    content = Path(page_path).read_text()\n",
    "    return bool(re.search(r'!\\[[^\\]]*\\]\\([^)]+\\)', content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_1.md'),\n",
       " Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_11.md'),\n",
       " Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_12.md'),\n",
       " Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_14.md'),\n",
       " Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_15.md'),\n",
       " Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_16.md'),\n",
       " Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_21.md'),\n",
       " Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_22.md'),\n",
       " Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_23.md'),\n",
       " Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_29.md'),\n",
       " Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_30.md'),\n",
       " Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_38.md'),\n",
       " Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_59.md'),\n",
       " Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_60.md'),\n",
       " Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_63.md'),\n",
       " Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_68.md'),\n",
       " Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_84.md'),\n",
       " Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_95.md'),\n",
       " Path('../_data/md_library/49d2fba781b6a7c0d94577479636ee6f/final_evaluation_report_final_olta_ndoja_pdf/enhanced/page_114.md')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "[page for page in pages if has_images(page)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class MarkdownPage: \n",
    "    \"A class to represent a markdown page\"\n",
    "    def __init__(self, path): self.path = Path(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class ImgRef(AttrDict):\n",
    "    \"A class to represent a image reference\"\n",
    "    def __repr__(self):\n",
    "        clean_context = self.context.replace('\\n', ' ')[:50] + \"...\"\n",
    "        fields = [f\"filename='{self.filename}'\", f\"context='{clean_context}'\"]\n",
    "        if hasattr(self, 'is_relevant'): fields.append(f\"is_relevant={self.is_relevant}\")\n",
    "        if hasattr(self, 'reason'): fields.append(f\"reason={self.reason}\")\n",
    "        # ... add other fields if present\n",
    "        return f\"ImgRef({', '.join(fields)})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def find_img_refs(\n",
    "    self:MarkdownPage, # Markdown page of interest\n",
    "    context_lines: int = 3, # Number of lines of context to include around the image\n",
    "    ):\n",
    "    \"Find all image references in the markdown page and include the context around the image\"\n",
    "    content = self.path.read_text()\n",
    "    lines = content.splitlines()\n",
    "    results = []\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        if re.search(r'!\\[[^\\]]*\\]\\(([^)]+)\\)', line):\n",
    "            # Extract context around this line\n",
    "            start = max(0, i - context_lines)\n",
    "            end = min(len(lines), i + context_lines + 1)\n",
    "            context = '\\n'.join(lines[start:end])\n",
    "            \n",
    "            # Extract image filename\n",
    "            match = re.search(r'!\\[[^\\]]*\\]\\(([^)]+)\\)', line)\n",
    "            results.append(ImgRef({\n",
    "                \"filename\": match.group(1),\n",
    "                \"context\": context\n",
    "            }))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "for page in pages: \n",
    "    img_refs = MarkdownPage(page).find_img_refs()\n",
    "    if img_refs: print(f\"In {page.stem}: {img_refs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class ImageRelevance(dspy.Signature):\n",
    "    \"\"\"Determine if an image contains substantive content for document understanding.\n",
    "    \n",
    "    RELEVANT: Charts, graphs, diagrams, figures, tables, screenshots, flowcharts\n",
    "    IRRELEVANT: Logos, cover images, decorative elements, headers, footers\n",
    "    \"\"\"\n",
    "    img_filename: str = dspy.InputField()\n",
    "    surrounding_context: str = dspy.InputField(desc=\"Text context around the image\")\n",
    "    is_relevant: bool = dspy.OutputField(desc=\"True only for substantive content like data visualizations\")\n",
    "    reason: str = dspy.OutputField(desc=\"Brief explanation of decision\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def classify_imgs(\n",
    "    self:MarkdownPage, # Markdown page of interest\n",
    "    img_refs: list[ImgRef], # List of image references\n",
    "    ):\n",
    "    \"Classify images in the markdown page\"\n",
    "    classifier = dspy.ChainOfThought(ImageRelevance)\n",
    "    for img_ref in img_refs:\n",
    "        result = classifier(\n",
    "            img_filename=img_ref.filename,\n",
    "            surrounding_context=img_ref.context,\n",
    "            page_nb=1  # We could make this dynamic if needed\n",
    "        )\n",
    "        img_ref.is_relevant = result.is_relevant\n",
    "        img_ref.reason = result.reason\n",
    "    return img_refs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ImgRef</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'img-0.jpeg'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">context</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' Final Evaluation Report, 17 March 2023  ![img-0.j...'</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;35mImgRef\u001b[0m\u001b[1m(\u001b[0m\u001b[33mfilename\u001b[0m=\u001b[32m'img-0.jpeg'\u001b[0m, \u001b[33mcontext\u001b[0m=\u001b[32m' Final Evaluation Report, 17 March 2023  !\u001b[0m\u001b[32m[\u001b[0m\u001b[32mimg-0.j...'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "img_refs = MarkdownPage(pages[0]).find_img_refs(); print(img_refs)\n",
    "md_page = MarkdownPage(pages[5]) \n",
    "img_refs = md_page.find_img_refs()\n",
    "clf_img_refs = md_page.classify_imgs(img_refs)\n",
    "print(clf_img_refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def describe_img(\n",
    "    img_path: Path, # Path to the image\n",
    "    context: str, # Context of the image\n",
    "    api_key: str = cfg.api_key, # API key for the LLM model\n",
    "    model: str = cfg.lm, # Model to use\n",
    "    ):\n",
    "    \"Describe an image using an LLM\"\n",
    "    with open(img_path, \"rb\") as image_file:\n",
    "        base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "    # Auto-detect image format\n",
    "    img_format = img_path.suffix.lower().replace('.', '')\n",
    "    if img_format == 'jpg': img_format = 'jpeg'\n",
    "    \n",
    "    prompt = f\"\"\"Provide a concise paragraph description of this image for evaluation report analysis. Include: type of content, main topic, key data/statistics, trends, and takeaways. Write as flowing text, not numbered points. Context: {context}\"\"\"\n",
    "    response = completion(\n",
    "        model=model,\n",
    "        messages=[{\n",
    "            \"role\": \"user\", \n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/{img_format};base64,{base64_image}\"}}\n",
    "            ]\n",
    "        }],\n",
    "        api_key=api_key\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def describe_imgs(\n",
    "    self:MarkdownPage, # Markdown page of interest\n",
    "    img_refs: list[ImgRef], # List of image references\n",
    "    img_dir: str # Image directory\n",
    "    ):\n",
    "    \"Describe images in the markdown page\"\n",
    "    for img_ref in img_refs:\n",
    "        if img_ref.is_relevant:\n",
    "            img_path = Path(img_dir) / img_ref.filename\n",
    "            description = describe_img(img_path, img_ref.context, GEMINI_API_KEY)\n",
    "            img_ref.description = description\n",
    "    return img_refs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# md_page = MarkdownPage(pages[5]) \n",
    "# img_refs = md_page.find_img_refs()\n",
    "# clf_img_refs = md_page.classify_imgs(img_refs)\n",
    "# img_refs_desc = md_page.describe_imgs(clf_img_refs, doc.parent / 'img')\n",
    "# print(img_refs_desc[0].description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def replace_imgs_with_desc(\n",
    "    self:MarkdownPage, # Markdown page of interest\n",
    "    img_refs, # List of image references\n",
    "    enriched_dir: str = cfg.enriched_dir, # Enriched directory\n",
    "    ):\n",
    "    \"Replace images with their descriptions in the markdown page\"\n",
    "    enriched_path = self.path.parent.parent / enriched_dir\n",
    "    enriched_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    content = self.path.read_text()\n",
    "    for img_ref in img_refs:\n",
    "        if img_ref.is_relevant and hasattr(img_ref, 'description'):\n",
    "            pattern = f'!\\\\[[^\\\\]]*\\\\]\\\\({re.escape(img_ref.filename)}\\\\)'\n",
    "            content = re.sub(pattern, img_ref.description, content)\n",
    "    \n",
    "    enriched_file = enriched_path / self.path.name\n",
    "    enriched_file.write_text(content)\n",
    "    return enriched_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def copy_page_to_enriched(\n",
    "    page, # Page to copy\n",
    "    enriched_dir: str = cfg.enriched_dir, # Enriched directory\n",
    "    ):\n",
    "    \"Copy a page to the enriched directory\"\n",
    "    enriched_path = page.parent.parent / enriched_dir\n",
    "    enriched_path.mkdir(exist_ok=True)\n",
    "    return shutil.copy(page, enriched_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def process_single_page(\n",
    "    page, # Page to process\n",
    "    img_dir, # Image directory\n",
    "    enriched_dir: str = cfg.enriched_dir, # Enriched directory\n",
    "    ):\n",
    "    \"Process a single page\"\n",
    "    md_page = MarkdownPage(page)\n",
    "    # Pipeline: find → classify → describe → replace\n",
    "    img_refs = md_page.find_img_refs()\n",
    "    \n",
    "    if not img_refs: return copy_page_to_enriched(page, enriched_dir)\n",
    "    \n",
    "    classified_refs = md_page.classify_imgs(img_refs)\n",
    "    time.sleep(0.5)\n",
    "    described_refs = md_page.describe_imgs(classified_refs, img_dir)\n",
    "    time.sleep(0.5)\n",
    "    return md_page.replace_imgs_with_desc(described_refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def enrich_images(\n",
    "    pages_dir, # Pages directory\n",
    "    img_dir, # Image directory\n",
    "    n_workers=2, # Number of workers\n",
    "    ):\n",
    "    \"Enrich images in the pages directory\"\n",
    "    pages = Path(pages_dir).ls(file_exts=\".md\")\n",
    "    \n",
    "    pages_with_imgs = []\n",
    "    for page in pages:\n",
    "        if has_images(page):\n",
    "            pages_with_imgs.append(page)\n",
    "        else:\n",
    "            copy_page_to_enriched(page)\n",
    "    \n",
    "    if pages_with_imgs:\n",
    "        process_fn = partial(process_single_page, img_dir=img_dir)\n",
    "        parallel(process_fn, pages_with_imgs, n_workers=n_workers, threadpool=True, progress=True)\n",
    "        \n",
    "    print(f\"✓ Processed {len(pages)} pages ({len(pages_with_imgs)} with images)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "enrich_images(doc, doc.parent / 'img', n_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "def md_plus_evaluation(\n",
    "    eval_id: str,  # Evaluation ID to process\n",
    "    md_dir: str = \"../data/md_library\",  # Directory containing markdown folders\n",
    "    overwrite: bool = False  # Overwrite if enhanced/enriched already exists\n",
    "):\n",
    "    \"Fix markdown headings and enrich images for an evaluation report\"\n",
    "    # Find the evaluation's markdown directory\n",
    "    eval_path = Path(md_dir) / eval_id\n",
    "    \n",
    "    if not eval_path.exists():\n",
    "        logging.error(f\"Markdown directory not found: {eval_path}\")\n",
    "        return\n",
    "    \n",
    "    # Find the actual report folder (first subdirectory)\n",
    "    report_dirs = [d for d in eval_path.iterdir() if d.is_dir() \n",
    "                   and d.name != cfg.enhanced_dir and d.name != cfg.enriched_dir]\n",
    "    \n",
    "    if not report_dirs:\n",
    "        logging.error(f\"No report directory found in {eval_path}\")\n",
    "        return\n",
    "    \n",
    "    doc_path = report_dirs[0]\n",
    "    \n",
    "    # Check if already processed\n",
    "    enhanced_path = doc_path / cfg.enhanced_dir\n",
    "    enriched_path = doc_path.parent / cfg.enriched_dir\n",
    "    \n",
    "    if (enhanced_path.exists() or enriched_path.exists()) and not overwrite:\n",
    "        logging.info(f\"Output already exists for {eval_id}. Use --overwrite to reprocess.\")\n",
    "        return\n",
    "    \n",
    "    # Clean up if overwriting\n",
    "    if overwrite:\n",
    "        if enhanced_path.exists():\n",
    "            shutil.rmtree(enhanced_path)\n",
    "        if enriched_path.exists():\n",
    "            shutil.rmtree(enriched_path)\n",
    "    \n",
    "    logging.info(f\"Processing {eval_id}: fixing headings...\")\n",
    "    fix_doc_hdgs(doc_path, force=overwrite)\n",
    "    \n",
    "    logging.info(f\"Processing {eval_id}: enriching images...\")\n",
    "    pages_dir = doc_path / cfg.enhanced_dir\n",
    "    img_dir = doc_path / cfg.img_dir\n",
    "    enrich_images(pages_dir, img_dir, n_workers=1)\n",
    "    \n",
    "    logging.info(f\"Completed processing {eval_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
